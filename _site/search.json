[
  {
    "objectID": "DataAnalysis1.html",
    "href": "DataAnalysis1.html",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "",
    "text": "Below is a list of libraries used in conjunction with the R programming language, Quarto, and Jupyter for the creation of this statistical analysis. All datasets and libraries needed were imported at the start of the quarto project. Data was imported into a GitHub Repository to access it directly. Access the repository. The raw data data was selected to include only the traits desired. This data is referred to as selected_data in the project code. The dataset data was modified to treat missing data as described in Section 4.3. This data is referred in this project as imputed_data\n\n\nCode\nimport math\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom itables import options, show\n\n# Import data\ndata = pd.read_csv('btk_de_basil_2024.csv')\n\n# Convert 'TimeStamp' column to datetime\ndata['TimeStamp'] = pd.to_datetime(data['TimeStamp'])\n\n# Get list of treatments in the dataset\ntreatments = data['Treatment'].unique()\n\n# Group data by treatment\ngrouped_data_treatment = data.groupby('Treatment')\n\n# Get numerical variables\nnumerical_variables = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n\n# Get categorical variables, excluding 'TimeStamp'\ncategorical_variables = [col for col in data.select_dtypes(include=['object', 'category']).columns if col != 'TimeStamp']\n\n# Descriptive analysis for numerical variables\nnumerical_descriptive_stats = {var: grouped_data_treatment[var].describe().transpose() for var in numerical_variables}\n\n# Descriptive analysis for categorical variables\ncategorical_descriptive_stats = {}\nfor var in categorical_variables:\n    counts = data.pivot_table(index='Treatment', columns=var, aggfunc='size', fill_value=0)\n    categorical_descriptive_stats[var] = counts\n\n# Function to create a descriptive analysis of a variable by treatment\ndef descriptive_analysis(variable):\n    if variable in numerical_descriptive_stats:\n        analysis = numerical_descriptive_stats[variable]\n        pd.set_option('display.max_columns', None)\n        pd.set_option('display.max_rows', None)\n        print(f\"Descriptive analysis for numeric variable '{variable}':\")\n        display(analysis)\n    elif variable in categorical_descriptive_stats:\n        analysis = categorical_descriptive_stats[variable]\n        pd.set_option('display.max_columns', None)\n        pd.set_option('display.max_rows', None)\n        print(f\"Descriptive analysis for categorical variable '{variable}':\")\n        display(analysis)\n    else:\n        print(f\"The variable '{variable}' is not in the dataset\")\n\n# Example usage\n# descriptive_analysis('PlantHeight')\n\n# Show lists of variables and treatments\nprint(\"Treatments available:\", treatments)\nprint(\"Numeric variables:\", numerical_variables)\nprint(\"Cualitative variables\", categorical_variables)\n\n# Only include the data of the final date of the experiment for data analysis\nfinal_date = '2024-05-25'\ndata_may25 = data[data['TimeStamp'] == final_date]\n\n# data.head()\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ngrouped_data_treatment.head()",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#sec-miss",
    "href": "DataAnalysis1.html#sec-miss",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.3 Missing Data Assessment",
    "text": "4.3 Missing Data Assessment\nThere is not really missing data, the cuantitative variables of the plant were measured every week, but the water stress incidents were taken every day because irrigation was made everyday by hand, so pandas library is used because it can handle missing data without the need to manipulate the data sheet.",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#sec-dis",
    "href": "DataAnalysis1.html#sec-dis",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.4 Frequency Distribution Analysis",
    "text": "4.4 Frequency Distribution Analysis\nFrom ?@fig-lysine-distribution, it is visually inferred that the data seems to be approximately normally distributed with a single peak and symmetric shape, however, it doesn´t follow exactly the bell curve, so it is needed to do a nromality test to make sure how the data is distributed.",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#normality-test",
    "href": "DataAnalysis1.html#normality-test",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "3.5 Normality Test",
    "text": "3.5 Normality Test\n#| label: tbl-normal-distribution\n#| tbl-cap: \"Shapiro_Wilk test results for lysine content\"\n#| warning: false\n\n#Test for normal distribution\nnormality &lt;- shapiro.test(imputed_data$Lysine.14.mgG)\nresult &lt;- data.frame(\n    W = normality$statistic,\n    Pvalue = normality$p.value\n)\nkable(result, align = \"llr\")\nThe Shapiro-Wilk normality test has a p-value of almost 0 which is far below any conventional alpha level (e.g., 0.05). despite the high W value, the test finds significant evidence to suggest that the lysine content does not follow a normal distribution. For that reason, this will be needed to take into account the correlation and regression analyses.",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#sec-corr",
    "href": "DataAnalysis1.html#sec-corr",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.6 Correlation analysis",
    "text": "4.6 Correlation analysis\n#| label: fig-correlation_yield\n#| fig-cap: \"Correlation analysis between Lysine content and Yield traits\"\n#| warning: false\n#| fig.width: 8\n#| fig.height: 4\n\n#Add a column in imputed data with Lysine content transformed to logaritmic values\nimputed_data$Lysine.14.mgG_log &lt;- log(imputed_data$Lysine.14.mgG)\n\n#Correlation analysis\ncor_value_yield &lt;- cor(imputed_data$Lysine.14.mgG_log, imputed_data$Yield_g, \nmethod = \"spearman\")\n\n# Correlation plot\nggplot(imputed_data, aes(x = Lysine.14.mgG_log, y = Yield_g)) +\n  geom_point(shape = 21, fill = '#0f993d', color = 'white', size = 3) +\n  annotate(\"text\", x = Inf, y = Inf, label = paste(\"Spearman Correlation: \", \n    round(cor_value_yield, 5)),\n           hjust = 1.1, vjust = 1.1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Lysine content  log(mg/g)\", y = \"Yield (g/plant)\") \n\n4.6.1 Correlation of Lysine content and TSW\n#| label: fig-correlation_tsw\n#| fig-cap: \"Correlation analysis between Lysine content and Thousand Seed Weight (TSW)\"\n#| warning: false\n\n#Correlation analysis\ncor_value_tsw &lt;- cor(imputed_data$Lysine.14.mgG_log, imputed_data$TSW, \nmethod = \"spearman\")\n\n# Correlation plot\nggplot(\n  imputed_data, aes(x = Lysine.14.mgG_log, y = TSW)) +\n  geom_point(shape = 21, fill = '#0f993d', color = 'white', size = 3) +\n  annotate(\"text\", x = Inf, y = Inf, label = paste(\"Spearman Correlation: \", \n  round(cor_value_tsw, 5)), hjust = 1.1, vjust = 1.1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Lysine content log(mg/g)\", y = \"TSW (g)\"\n)\nAs can be seen, the correlation level between yield variables and lysine content is moderately positive (0.30 with yield and 0.39 with TSW) similar as reported in Craine et al. (2023), indicating that when the lysine content in quinoa seeds is higher, the yield and TSW will also be higher.",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#sec-reg",
    "href": "DataAnalysis1.html#sec-reg",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.7 Regression analysis",
    "text": "4.7 Regression analysis\n\n4.7.1 Regression analysis and ecuation of Lysine content and Yield\nThis analysis is crucial for understanding the relationship between these two variables, indicating whether higher lysine content correlates with higher yield. In ?@tbl-regression_yield, it is observed that the p-value is less than 0.05, leading to the rejection of the null hypothesis and the conclusion that there is a significant relationship between lysine content and yield. Furthermore, the R^2 value indicates that approximately 10% of the variability in Yield_g is explained by the model. This suggests that there are other factors influencing the yield that are not accounted for in this analysis. Additionally, this analysis is based on a single value derived from many, so it was expected that lysine content would not explain the entire model. For this same reason, the reported regression equation will not be as precise for determining yield values.\n#| label: tbl-regression_yield\n#| tbl-cap: \"Regression analysis between Lysine content and Yield\"\n#| warning: false\n\n#Regression analysis \nreg1_yield &lt;- lm(Yield_g ~ Lysine.14.mgG_log, data = imputed_data)\nsum_reg1_yield &lt;- summary(reg1_yield)\nbroom_yield_summary &lt;- broom::glance(sum_reg1_yield)\nknitr::kable(broom_yield_summary, align = \"llllllrr\")\n#| label: coef_yield\n#| warning: false\n#| cap: \"Regression ecuation between Lysine content and Yield\"\n\n#Regression and coefficient analysis\ncoefs_yield &lt;- coef(reg1_yield)\npaste(\"Y =\", coefs_yield[1], \"+\", coefs_yield[2], \"* X\")\n\n\n4.7.2 Regression analysis and ecuation of Lysine content and Thousand Seed Weight TSW\nThe outcome of this analysis delineates the potential relationship between lysine content and Thousand Seed Weight (TSW). Similar to the previous regression analysis, the null hypothesis can be rejected, leading to the conclusion that there is a highly significant relationship between lysine content and TSW. However, the R^2 value is quite low (13%), indicating that there are other factors affecting TSW that are not considered in this analysis, which was to be expected.\n#| label: tbl-regression_tsw\n#| tbl-cap: \"Regression analysis between Lysine content and Thousand Seed Weight (TSW)\"\n#| warning: false\n\n#Regression analysis \nreg1_tsw &lt;- lm(TSW ~ Lysine.14.mgG_log, data = imputed_data)\nsum_reg1_tsw &lt;- summary(reg1_tsw)\nbroom_tsw_summary &lt;- broom::glance(sum_reg1_tsw)\nknitr::kable(broom_tsw_summary, align = \"llllllrr\")\n#| label: coef_tsw\n#| warning: false\n#| cap: \"Regression ecuation between Lysine content and Thousand Seed Weight (TSW)\"\n\n#Regression and coefficient analysis\ncoefs_yield &lt;- coef(reg1_tsw)\npaste(\"Y =\", coefs_yield[1], \"+\", coefs_yield[2], \"* X\")",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis2.html",
    "href": "DataAnalysis2.html",
    "title": "Data analysis 2",
    "section": "",
    "text": "This project provides provides a simple scaffold for creating a Quarto Confluence Project. You’ll almost certainly want to remove the sample files, they are just here as examples. When you add you own documents (including ones in subfolders) they will be automatically added to the site navigation sidebar.",
    "crumbs": [
      "Data analysis 2"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#plant-height",
    "href": "DataAnalysis1.html#plant-height",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.1 Plant Height",
    "text": "4.1 Plant Height\n\n4.1.1 Descriptive analysis\n\n\nCode\ndescr_analysis_PlantHeight = grouped_data_treatment['PlantHeight'].describe().transpose()\n# Set display options to show all columns and rows\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Print the full descriptive statistics table\nshow(descr_analysis_PlantHeight, \"\")\n\n\n\n\nTable 1: Descriptive analysis of Plant Height\n\n\n\n\n\n    \n      Treatment\n      B100\n      B80\n      C100\n      C80\n      Control\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.0 from the internet...\n(need help?)\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Normality Test\nDebido a que se tiene una muestra total\n\n\nCode\nfrom scipy.stats import shapiro, kstest, anderson\nimport scipy.stats as stats\nnormality_results = {}\nvariables = ['PlantHeight', 'StemDiameter', 'LeafArea', 'LeafNumber']\n\n# Normality test for every treatment and variable\nfor Treatment, group in grouped_data_treatment:\n    normality_results[Treatment] = {}\n    for variable in variables:\n        # filter non-null data\n        valid_data = group[variable].dropna()\n        if len(valid_data) &gt; 0:  # Validation that there is enough data to test\n            # Shapiro-Wilk test\n            shapiro_test = shapiro(valid_data)\n            # Kolmogorov-Smirnov test\n            ks_test = kstest(valid_data, 'norm')\n            # Anderson-Darling test\n            anderson_test = anderson(valid_data)\n\n            # Save results\n            normality_results[Treatment][variable] = {\n                'Shapiro-Wilk': shapiro_test,\n                'Kolmogorov-Smirnov': ks_test,\n                'Anderson-Darling': anderson_test\n            }\n\n# Show results\n#import pprint\n#pprint.pprint(normality_results)\n#print(normality_results)\n\ndef plot_histogram_qq(data, treatment, variable, normality_results):\n    valid_data = data[data['Treatment'] == treatment][variable].dropna()\n    \n    if len(valid_data) &gt; 0:\n        # Histograma\n        plt.figure(figsize=(12, 6))\n        plt.subplot(1, 2, 1)\n        plt.hist(valid_data, bins=10, color='blue', edgecolor='black', alpha=0.7)\n        plt.title(f'Histogram of Frequency for {variable} ({treatment})')\n        plt.xlabel(variable)\n        plt.ylabel('Frecuency')\n        \n        # Gráfico Q-Q\n        plt.subplot(1, 2, 2)\n        stats.probplot(valid_data, dist=\"norm\", plot=plt)\n        plt.title(f'Q-Q Graphic of {variable} ({treatment})')\n        plt.xlabel('Normal Theoretical quantiles')\n        plt.ylabel('Normal Data Quantiles')\n        \n        # Obtener resultados de los tests\n        shapiro_res = normality_results[treatment][variable]['Shapiro-Wilk']\n        ks_res = normality_results[treatment][variable]['Kolmogorov-Smirnov']\n        anderson_res = normality_results[treatment][variable]['Anderson-Darling']\n        \n        # Crear texto descriptivo\n        description = (f\"Shapiro-Wilk p-value: {shapiro_res.pvalue:.3e}\\n\"\n                       f\"Kolmogorov-Smirnov p-value: {ks_res.pvalue:.3e}\\n\"\n                       f\"Anderson-Darling statistic: {anderson_res.statistic:.3f}\")\n        \n        # Add descriptive text to histogram\n        plt.subplot(1, 2, 1)\n        plt.text(0.95, 0.95, description, transform=plt.gca().transAxes, fontsize=10,\n                 verticalalignment='top', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5))\n        \n        # Show graphics\n        plt.tight_layout()\n        plt.show()\n        \n        # Normality test\n        print(\"Normality analysis\")\n        print(f\"Shapiro-Wilk p-value: {shapiro_res.pvalue:.3e} ({'Not enough evidence to reject' if shapiro_res.pvalue &gt; 0.05 else 'Rejects'} Normality hipothesis)\")\n        print(f\"Kolmogorov-Smirnov p-value: {ks_res.pvalue:.3e} ({'Not enough evidence to reject' if ks_res.pvalue &gt; 0.05 else 'Rejects'} Normality hipothesis)\")\n        print(f\"Anderson-Darling statistic: {anderson_res.statistic:.3f} (Compare with critical values: {anderson_res.critical_values})\")\n    else:\n        print(f\"Not enough data for {variable} in treatment {treatment}\")\n\n\n# Example of use for treatment B100 and PlantHeight Variable\nplot_histogram_qq(data, 'B80', 'PlantHeight', normality_results)\n\n\nNormality analysis\nShapiro-Wilk p-value: 4.529e-02 (Rejects Normality hipothesis)\nKolmogorov-Smirnov p-value: 3.797e-79 (Rejects Normality hipothesis)\nAnderson-Darling statistic: 0.771 (Compare with critical values: [0.523 0.596 0.715 0.834 0.992])\n\n\n\n\nTable 2: Normality test of Plant Height by treatment\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.3 Frequency Distribution\n\n\nCode\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))\naxes = axes.flatten()\n\n\nfor ax, (treatment, group) in zip(axes, grouped_data_treatment):\n    ax.hist(group['PlantHeight'], bins=10, edgecolor='black', alpha=0.7)\n    ax.set_title(f'Frequency Distribution of Plant Height for Treatment {treatment}')\n    ax.set_xlabel('Plant Height')\n    ax.set_ylabel('Frequency')\n    ax.grid(axis='y', alpha=0.75)\n\n# Hide any empty subplots\nfor i in range(len(grouped_data_treatment), len(axes)):\n    fig.delaxes(axes[i])\n\n# Adjust layout\nplt.tight_layout()\n\n# Save the combined figure as an image\nplt.savefig('combined_histograms.png')\n\n# Show the combined figure\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#stem-diameter",
    "href": "DataAnalysis1.html#stem-diameter",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.2 Stem Diameter",
    "text": "4.2 Stem Diameter\n\n4.2.1 Descriptive analysis\n\n\nCode\ndescr_analysis_StemDiam = grouped_data_treatment['StemDiameter'].describe().transpose()\n# Set display options to show all columns and rows\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Print the full descriptive statistics table\nshow(descr_analysis_StemDiam, \"\")\n\n\n\n\nTable 3: Descriptive analysis of Stem Diameter\n\n\n\n\n\n    \n      Treatment\n      B100\n      B80\n      C100\n      C80\n      Control\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.0 from the internet...\n(need help?)",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  },
  {
    "objectID": "DataAnalysis1.html#normality-test-1",
    "href": "DataAnalysis1.html#normality-test-1",
    "title": "Basil Water Stress Experiment 1 DE 2024 | Data Analysis",
    "section": "4.5 Normality Test",
    "text": "4.5 Normality Test\n#| label: tbl-normal-distribution\n#| tbl-cap: \"Shapiro_Wilk test results for lysine content\"\n#| warning: false\n\n#Test for normal distribution\nnormality &lt;- shapiro.test(imputed_data$Lysine.14.mgG)\nresult &lt;- data.frame(\n    W = normality$statistic,\n    Pvalue = normality$p.value\n)\nkable(result, align = \"llr\")\nThe Shapiro-Wilk normality test has a p-value of almost 0 which is far below any conventional alpha level (e.g., 0.05). despite the high W value, the test finds significant evidence to suggest that the lysine content does not follow a normal distribution. For that reason, this will be needed to take into account the correlation and regression analyses.",
    "crumbs": [
      "Basil Water Stress Experiment 1 DE 2024 | Data Analysis"
    ]
  }
]